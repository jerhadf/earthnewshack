{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import parse_data\n",
    "import json\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_name</th>\n",
       "      <th>date_published</th>\n",
       "      <th>date_uploaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The urgency of tackling climate change seems, ...</td>\n",
       "      <td>The left’s belated, and bittersweet, victory o...</td>\n",
       "      <td>the-lefts-belated-and-bittersweet-victory-on-c...</td>\n",
       "      <td>2020-10-15 08:42:11.000000</td>\n",
       "      <td>2022-10-10 06:30:30.489907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Summer 2022 risks being a ‘perfect storm for g...</td>\n",
       "      <td>Climate change threatens Europe’s once ‘placid...</td>\n",
       "      <td>climate-change-threatens-europes-once-placid-a...</td>\n",
       "      <td>2022-07-04 18:48:55.000000</td>\n",
       "      <td>2022-10-10 06:30:33.769609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>With Egypt’s COP27 less than six months away, ...</td>\n",
       "      <td>Can MENA countries fight climate change the sa...</td>\n",
       "      <td>can-mena-countries-fight-climate-change-the-sa...</td>\n",
       "      <td>2022-06-11 20:34:08.000000</td>\n",
       "      <td>2022-10-10 06:30:38.083833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Red Cross says the world has been hit by more ...</td>\n",
       "      <td>Global warming bigger threat than coronavirus:...</td>\n",
       "      <td>climate-change-bigger-threat-than-covid-red-cross</td>\n",
       "      <td>2020-11-17 10:28:01.000000</td>\n",
       "      <td>2022-10-10 06:30:38.588857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Therefore, climate action should be central to...</td>\n",
       "      <td>The coronavirus outbreak is part of the climat...</td>\n",
       "      <td>the-coronavirus-outbreak-is-part-of-the-climat...</td>\n",
       "      <td>2020-03-30 12:35:44.000000</td>\n",
       "      <td>2022-10-10 06:30:39.636792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8503</th>\n",
       "      <td>8504</td>\n",
       "      <td>Sign in with research by Vanessa Montalbano Go...</td>\n",
       "      <td>Nikki Haley wants to address climate change n...</td>\n",
       "      <td>nikki-haley-wants-address-climate-change-not-b...</td>\n",
       "      <td>2023-02-15 12:38:23.000000</td>\n",
       "      <td>2023-02-16 04:33:42.722584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8504</th>\n",
       "      <td>8505</td>\n",
       "      <td>Sign in No one knows for sure what happened to...</td>\n",
       "      <td>Drought may have doomed this ancient empire — ...</td>\n",
       "      <td>climate-change-drought-history</td>\n",
       "      <td>2023-02-08 16:00:00.000000</td>\n",
       "      <td>2023-02-17 04:24:44.596090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8505</th>\n",
       "      <td>8506</td>\n",
       "      <td>Sign in Both heat and cold can kill. But cold ...</td>\n",
       "      <td>Will global warming make temperature less deadly?</td>\n",
       "      <td>hot-cold-extreme-temperature-deaths</td>\n",
       "      <td>2023-02-16 11:30:48.000000</td>\n",
       "      <td>2023-02-23 03:55:44.057875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8506</th>\n",
       "      <td>8507</td>\n",
       "      <td>Sign in A previous version of this article mis...</td>\n",
       "      <td>How this company plans to use Earth’s heat to ...</td>\n",
       "      <td>geothermal-direct-air-capture-fervo</td>\n",
       "      <td>2023-02-23 12:00:00.000000</td>\n",
       "      <td>2023-02-27 16:34:23.256344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8507</th>\n",
       "      <td>8508</td>\n",
       "      <td>Sign in Global warming will reshape the econom...</td>\n",
       "      <td>Which U.S. cities will fare best in a warming ...</td>\n",
       "      <td>us-cities-climate-vulnerability</td>\n",
       "      <td>2023-02-23 13:30:00.000000</td>\n",
       "      <td>2023-02-27 16:34:37.417232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8508 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               body  \\\n",
       "0        1  The urgency of tackling climate change seems, ...   \n",
       "1        2  Summer 2022 risks being a ‘perfect storm for g...   \n",
       "2        3  With Egypt’s COP27 less than six months away, ...   \n",
       "3        4  Red Cross says the world has been hit by more ...   \n",
       "4        5  Therefore, climate action should be central to...   \n",
       "...    ...                                                ...   \n",
       "8503  8504  Sign in with research by Vanessa Montalbano Go...   \n",
       "8504  8505  Sign in No one knows for sure what happened to...   \n",
       "8505  8506  Sign in Both heat and cold can kill. But cold ...   \n",
       "8506  8507  Sign in A previous version of this article mis...   \n",
       "8507  8508  Sign in Global warming will reshape the econom...   \n",
       "\n",
       "                                               headline  \\\n",
       "0     The left’s belated, and bittersweet, victory o...   \n",
       "1     Climate change threatens Europe’s once ‘placid...   \n",
       "2     Can MENA countries fight climate change the sa...   \n",
       "3     Global warming bigger threat than coronavirus:...   \n",
       "4     The coronavirus outbreak is part of the climat...   \n",
       "...                                                 ...   \n",
       "8503   Nikki Haley wants to address climate change n...   \n",
       "8504  Drought may have doomed this ancient empire — ...   \n",
       "8505  Will global warming make temperature less deadly?   \n",
       "8506  How this company plans to use Earth’s heat to ...   \n",
       "8507  Which U.S. cities will fare best in a warming ...   \n",
       "\n",
       "                                           article_name  \\\n",
       "0     the-lefts-belated-and-bittersweet-victory-on-c...   \n",
       "1     climate-change-threatens-europes-once-placid-a...   \n",
       "2     can-mena-countries-fight-climate-change-the-sa...   \n",
       "3     climate-change-bigger-threat-than-covid-red-cross   \n",
       "4     the-coronavirus-outbreak-is-part-of-the-climat...   \n",
       "...                                                 ...   \n",
       "8503  nikki-haley-wants-address-climate-change-not-b...   \n",
       "8504                     climate-change-drought-history   \n",
       "8505                hot-cold-extreme-temperature-deaths   \n",
       "8506                geothermal-direct-air-capture-fervo   \n",
       "8507                    us-cities-climate-vulnerability   \n",
       "\n",
       "                  date_published               date_uploaded  \n",
       "0     2020-10-15 08:42:11.000000  2022-10-10 06:30:30.489907  \n",
       "1     2022-07-04 18:48:55.000000  2022-10-10 06:30:33.769609  \n",
       "2     2022-06-11 20:34:08.000000  2022-10-10 06:30:38.083833  \n",
       "3     2020-11-17 10:28:01.000000  2022-10-10 06:30:38.588857  \n",
       "4     2020-03-30 12:35:44.000000  2022-10-10 06:30:39.636792  \n",
       "...                          ...                         ...  \n",
       "8503  2023-02-15 12:38:23.000000  2023-02-16 04:33:42.722584  \n",
       "8504  2023-02-08 16:00:00.000000  2023-02-17 04:24:44.596090  \n",
       "8505  2023-02-16 11:30:48.000000  2023-02-23 03:55:44.057875  \n",
       "8506  2023-02-23 12:00:00.000000  2023-02-27 16:34:23.256344  \n",
       "8507  2023-02-23 13:30:00.000000  2023-02-27 16:34:37.417232  \n",
       "\n",
       "[8508 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_json_db(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def create_dataframe(data):\n",
    "    df = pd.DataFrame(data=data)\n",
    "    return df\n",
    "# Example usage\n",
    "file_path = \"db.sqlite.json\"\n",
    "data = load_json_db(file_path)\n",
    "df = create_dataframe(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 521/8508 [1:28:05<22:30:28, 10.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m     body \u001b[39m=\u001b[39m body[:\u001b[39m12800\u001b[39m]\n\u001b[0;32m     12\u001b[0m summary \u001b[39m=\u001b[39m parse_data\u001b[39m.\u001b[39mgenerate_summary(body)\n\u001b[1;32m---> 14\u001b[0m explanation, level \u001b[39m=\u001b[39m parse_data\u001b[39m.\u001b[39;49mextract_explanation(summary)\n\u001b[0;32m     16\u001b[0m locations_df \u001b[39m=\u001b[39m parse_data\u001b[39m.\u001b[39mextract_loc(body)\n\u001b[0;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(locations_df) \u001b[39m<\u001b[39m\u001b[39m9\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\gabri\\Desktop\\HackDartmouth\\earthnewshack\\parse_data.py:55\u001b[0m, in \u001b[0;36mextract_explanation\u001b[1;34m(input_text, level)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_explanation\u001b[39m(input_text, level\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcollege student\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     54\u001b[0m     prompt \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou are a climate scientist that explains things at a 8th grade level. Define the 2-4 most complicated climate-change related words in the following text:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00minput_text\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m     completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     56\u001b[0m             model \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     57\u001b[0m             messages \u001b[39m=\u001b[39;49m [\n\u001b[0;32m     58\u001b[0m                 {\u001b[39m'\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m: prompt}\n\u001b[0;32m     59\u001b[0m             ],\n\u001b[0;32m     60\u001b[0m         )\n\u001b[0;32m     62\u001b[0m     explanation \u001b[39m=\u001b[39m completion[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m explanation, level\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\site-packages\\openai\\api_requestor.py:216\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[0;32m    219\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    220\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    221\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    222\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    223\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[0;32m    226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\site-packages\\openai\\api_requestor.py:516\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m     _thread_context\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m _make_session()\n\u001b[0;32m    515\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 516\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    517\u001b[0m         method,\n\u001b[0;32m    518\u001b[0m         abs_url,\n\u001b[0;32m    519\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    520\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    521\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    522\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    523\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[0;32m    524\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[0;32m    525\u001b[0m     )\n\u001b[0;32m    526\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    527\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m         )\n\u001b[0;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#new_df = pd.DataFrame(columns=['id', 'body', 'headline', 'article_name', 'date_published', 'date_uploaded', 'summary', 'explanation', 'address', 'lat', 'lon'])\n",
    "new_df = pd.read_csv('main_dataset.csv')\n",
    "for i in tqdm.tqdm(range(0, len(df))):\n",
    "    if i % 50 == 0:\n",
    "        new_df.to_csv(f'main_dataset_{i}.csv')\n",
    "    article = df.iloc[i]\n",
    "    body = article['body']\n",
    "\n",
    "    if len(body) > 12800:\n",
    "        body = body[:12800]\n",
    "    \n",
    "    summary = parse_data.generate_summary(body)\n",
    "    \n",
    "    explanation, level = parse_data.extract_explanation(summary)\n",
    "\n",
    "    locations_df = parse_data.extract_loc(body)\n",
    "\n",
    "    temp_df = pd.DataFrame(columns=['id', 'body', 'headline', 'article_name', 'date_published', 'date_uploaded', 'summary', 'explanation', 'address', 'lat', 'lon'])\n",
    "    if len(locations_df) <9:\n",
    "        for j in range(len(locations_df)):\n",
    "            temp_df = pd.concat([temp_df, pd.DataFrame({'id': [article['id']], 'body': [article['body']], 'headline': [article['headline']], 'article_name': [article['article_name']], 'date_published': [article['date_published']], 'date_uploaded': [article['date_uploaded']], 'summary': [summary], 'explanation': [explanation], 'address': [locations_df.iloc[j]['address']], 'lat': [locations_df.iloc[j]['latitude']], 'lon': [locations_df.iloc[j]['longitude']]} )], ignore_index=True)\n",
    "    else:\n",
    "        for j in range(8):\n",
    "            temp_df = pd.concat([temp_df, pd.DataFrame({'id': [article['id']], 'body': [article['body']], 'headline': [article['headline']], 'article_name': [article['article_name']], 'date_published': [article['date_published']], 'date_uploaded': [article['date_uploaded']], 'summary': [summary], 'explanation': [explanation], 'address': [locations_df.iloc[j]['address']], 'lat': [locations_df.iloc[j]['latitude']], 'lon': [locations_df.iloc[j]['longitude']]} )], ignore_index=True)\n",
    "    \n",
    "    new_df = pd.concat([new_df, temp_df], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "for i in range(50, 550, 50):\n",
    "    if df is None:\n",
    "        df = pd.read_csv(f'./main_dataset_{i}.csv')\n",
    "    else:\n",
    "        df = pd.concat([df, pd.read_csv(f'./main_dataset_{i}.csv')], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.4</th>\n",
       "      <th>Unnamed: 0.3</th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_name</th>\n",
       "      <th>date_published</th>\n",
       "      <th>date_uploaded</th>\n",
       "      <th>summary</th>\n",
       "      <th>explanation</th>\n",
       "      <th>address</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>The urgency of tackling climate change seems, ...</td>\n",
       "      <td>The left’s belated, and bittersweet, victory o...</td>\n",
       "      <td>the-lefts-belated-and-bittersweet-victory-on-c...</td>\n",
       "      <td>2020-10-15 08:42:11.000000</td>\n",
       "      <td>2022-10-10 06:30:30.489907</td>\n",
       "      <td>The urgency of tackling climate change seems t...</td>\n",
       "      <td>1. Emissions: the release of gases into the ai...</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.783730</td>\n",
       "      <td>-100.445882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>The urgency of tackling climate change seems, ...</td>\n",
       "      <td>The left’s belated, and bittersweet, victory o...</td>\n",
       "      <td>the-lefts-belated-and-bittersweet-victory-on-c...</td>\n",
       "      <td>2020-10-15 08:42:11.000000</td>\n",
       "      <td>2022-10-10 06:30:30.489907</td>\n",
       "      <td>The urgency of tackling climate change seems t...</td>\n",
       "      <td>1. Emissions: the release of gases into the ai...</td>\n",
       "      <td>Australia</td>\n",
       "      <td>-24.776109</td>\n",
       "      <td>134.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>The urgency of tackling climate change seems, ...</td>\n",
       "      <td>The left’s belated, and bittersweet, victory o...</td>\n",
       "      <td>the-lefts-belated-and-bittersweet-victory-on-c...</td>\n",
       "      <td>2020-10-15 08:42:11.000000</td>\n",
       "      <td>2022-10-10 06:30:30.489907</td>\n",
       "      <td>The urgency of tackling climate change seems t...</td>\n",
       "      <td>1. Emissions: the release of gases into the ai...</td>\n",
       "      <td>中国</td>\n",
       "      <td>35.000074</td>\n",
       "      <td>104.999927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>The urgency of tackling climate change seems, ...</td>\n",
       "      <td>The left’s belated, and bittersweet, victory o...</td>\n",
       "      <td>the-lefts-belated-and-bittersweet-victory-on-c...</td>\n",
       "      <td>2020-10-15 08:42:11.000000</td>\n",
       "      <td>2022-10-10 06:30:30.489907</td>\n",
       "      <td>The urgency of tackling climate change seems t...</td>\n",
       "      <td>1. Emissions: the release of gases into the ai...</td>\n",
       "      <td>Ōu</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>The urgency of tackling climate change seems, ...</td>\n",
       "      <td>The left’s belated, and bittersweet, victory o...</td>\n",
       "      <td>the-lefts-belated-and-bittersweet-victory-on-c...</td>\n",
       "      <td>2020-10-15 08:42:11.000000</td>\n",
       "      <td>2022-10-10 06:30:30.489907</td>\n",
       "      <td>The urgency of tackling climate change seems t...</td>\n",
       "      <td>1. Emissions: the release of gases into the ai...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>54.702354</td>\n",
       "      <td>-3.276575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>481</td>\n",
       "      <td>How fundamentally different views about climat...</td>\n",
       "      <td>Donald Trump and California: A battle of wildf...</td>\n",
       "      <td>donald-trump-and-california-a-battle-of-wildfi...</td>\n",
       "      <td>2020-07-30 12:01:38.000000</td>\n",
       "      <td>2022-10-10 07:00:25.099338</td>\n",
       "      <td>The 2020 US election will hinge on differing v...</td>\n",
       "      <td>1. Emissions Regulations: Rules and laws that ...</td>\n",
       "      <td>Hollywood, Los Angeles, Los Angeles County, CA...</td>\n",
       "      <td>34.098003</td>\n",
       "      <td>-118.329523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>487</td>\n",
       "      <td>A much less costly way to regenerate our fores...</td>\n",
       "      <td>Reforestation is not necessarily about plantin...</td>\n",
       "      <td>reforestation-is-not-necessarily-about-plantin...</td>\n",
       "      <td>2020-01-18 11:00:56.000000</td>\n",
       "      <td>2022-10-10 07:00:54.286876</td>\n",
       "      <td>Assisted natural regeneration, a low-tech and ...</td>\n",
       "      <td>1. Assisted natural regeneration - This means ...</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>-10.333333</td>\n",
       "      <td>-53.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>492</td>\n",
       "      <td>Publication by the UN, Red Cross says 38 heatw...</td>\n",
       "      <td>Future heatwaves will lead to large ‘loss of l...</td>\n",
       "      <td>future-heatwaves-will-lead-to-large-loss-of-li...</td>\n",
       "      <td>2022-10-10 13:46:17.000000</td>\n",
       "      <td>2022-10-17 21:12:18.867964</td>\n",
       "      <td>A report by the United Nations and the Red Cro...</td>\n",
       "      <td>1. Unsustainable - This means that something c...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>51.208697</td>\n",
       "      <td>89.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>516</td>\n",
       "      <td>The nomads who have travelled around Mongolia’...</td>\n",
       "      <td>In Mongolia, climate crisis threatens herding ...</td>\n",
       "      <td>in-mongolias-tsaikhir-valley-climate-risks-anc...</td>\n",
       "      <td>2022-11-29 01:59:12.000000</td>\n",
       "      <td>2022-12-03 11:43:34.468105</td>\n",
       "      <td>Nomadic herders in Mongolia's Tsaikhir Valley ...</td>\n",
       "      <td>1. Drought - a prolonged period of dry weather...</td>\n",
       "      <td>Монгол улс ᠮᠤᠩᠭᠤᠯ ᠤᠯᠤᠰ</td>\n",
       "      <td>46.825039</td>\n",
       "      <td>103.849974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>516</td>\n",
       "      <td>The nomads who have travelled around Mongolia’...</td>\n",
       "      <td>In Mongolia, climate crisis threatens herding ...</td>\n",
       "      <td>in-mongolias-tsaikhir-valley-climate-risks-anc...</td>\n",
       "      <td>2022-11-29 01:59:12.000000</td>\n",
       "      <td>2022-12-03 11:43:34.468105</td>\n",
       "      <td>Nomadic herders in Mongolia's Tsaikhir Valley ...</td>\n",
       "      <td>1. Drought - a prolonged period of dry weather...</td>\n",
       "      <td>Монгол улс ᠮᠤᠩᠭᠤᠯ ᠤᠯᠤᠰ</td>\n",
       "      <td>46.825039</td>\n",
       "      <td>103.849974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>447 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.4  Unnamed: 0.3  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0   id  \\\n",
       "0             0.0           0.0           0.0           0.0         0.0    1   \n",
       "1             1.0           1.0           1.0           1.0         1.0    1   \n",
       "2             2.0           2.0           2.0           2.0         2.0    1   \n",
       "3             3.0           3.0           3.0           3.0         3.0    1   \n",
       "4             4.0           4.0           4.0           4.0         4.0    1   \n",
       "..            ...           ...           ...           ...         ...  ...   \n",
       "442           NaN           NaN           NaN           NaN         NaN  481   \n",
       "443           NaN           NaN           NaN           NaN         NaN  487   \n",
       "444           NaN           NaN           NaN           NaN         NaN  492   \n",
       "445           NaN           NaN           NaN           NaN         NaN  516   \n",
       "446           NaN           NaN           NaN           NaN         NaN  516   \n",
       "\n",
       "                                                  body  \\\n",
       "0    The urgency of tackling climate change seems, ...   \n",
       "1    The urgency of tackling climate change seems, ...   \n",
       "2    The urgency of tackling climate change seems, ...   \n",
       "3    The urgency of tackling climate change seems, ...   \n",
       "4    The urgency of tackling climate change seems, ...   \n",
       "..                                                 ...   \n",
       "442  How fundamentally different views about climat...   \n",
       "443  A much less costly way to regenerate our fores...   \n",
       "444  Publication by the UN, Red Cross says 38 heatw...   \n",
       "445  The nomads who have travelled around Mongolia’...   \n",
       "446  The nomads who have travelled around Mongolia’...   \n",
       "\n",
       "                                              headline  \\\n",
       "0    The left’s belated, and bittersweet, victory o...   \n",
       "1    The left’s belated, and bittersweet, victory o...   \n",
       "2    The left’s belated, and bittersweet, victory o...   \n",
       "3    The left’s belated, and bittersweet, victory o...   \n",
       "4    The left’s belated, and bittersweet, victory o...   \n",
       "..                                                 ...   \n",
       "442  Donald Trump and California: A battle of wildf...   \n",
       "443  Reforestation is not necessarily about plantin...   \n",
       "444  Future heatwaves will lead to large ‘loss of l...   \n",
       "445  In Mongolia, climate crisis threatens herding ...   \n",
       "446  In Mongolia, climate crisis threatens herding ...   \n",
       "\n",
       "                                          article_name  \\\n",
       "0    the-lefts-belated-and-bittersweet-victory-on-c...   \n",
       "1    the-lefts-belated-and-bittersweet-victory-on-c...   \n",
       "2    the-lefts-belated-and-bittersweet-victory-on-c...   \n",
       "3    the-lefts-belated-and-bittersweet-victory-on-c...   \n",
       "4    the-lefts-belated-and-bittersweet-victory-on-c...   \n",
       "..                                                 ...   \n",
       "442  donald-trump-and-california-a-battle-of-wildfi...   \n",
       "443  reforestation-is-not-necessarily-about-plantin...   \n",
       "444  future-heatwaves-will-lead-to-large-loss-of-li...   \n",
       "445  in-mongolias-tsaikhir-valley-climate-risks-anc...   \n",
       "446  in-mongolias-tsaikhir-valley-climate-risks-anc...   \n",
       "\n",
       "                 date_published               date_uploaded  \\\n",
       "0    2020-10-15 08:42:11.000000  2022-10-10 06:30:30.489907   \n",
       "1    2020-10-15 08:42:11.000000  2022-10-10 06:30:30.489907   \n",
       "2    2020-10-15 08:42:11.000000  2022-10-10 06:30:30.489907   \n",
       "3    2020-10-15 08:42:11.000000  2022-10-10 06:30:30.489907   \n",
       "4    2020-10-15 08:42:11.000000  2022-10-10 06:30:30.489907   \n",
       "..                          ...                         ...   \n",
       "442  2020-07-30 12:01:38.000000  2022-10-10 07:00:25.099338   \n",
       "443  2020-01-18 11:00:56.000000  2022-10-10 07:00:54.286876   \n",
       "444  2022-10-10 13:46:17.000000  2022-10-17 21:12:18.867964   \n",
       "445  2022-11-29 01:59:12.000000  2022-12-03 11:43:34.468105   \n",
       "446  2022-11-29 01:59:12.000000  2022-12-03 11:43:34.468105   \n",
       "\n",
       "                                               summary  \\\n",
       "0    The urgency of tackling climate change seems t...   \n",
       "1    The urgency of tackling climate change seems t...   \n",
       "2    The urgency of tackling climate change seems t...   \n",
       "3    The urgency of tackling climate change seems t...   \n",
       "4    The urgency of tackling climate change seems t...   \n",
       "..                                                 ...   \n",
       "442  The 2020 US election will hinge on differing v...   \n",
       "443  Assisted natural regeneration, a low-tech and ...   \n",
       "444  A report by the United Nations and the Red Cro...   \n",
       "445  Nomadic herders in Mongolia's Tsaikhir Valley ...   \n",
       "446  Nomadic herders in Mongolia's Tsaikhir Valley ...   \n",
       "\n",
       "                                           explanation  \\\n",
       "0    1. Emissions: the release of gases into the ai...   \n",
       "1    1. Emissions: the release of gases into the ai...   \n",
       "2    1. Emissions: the release of gases into the ai...   \n",
       "3    1. Emissions: the release of gases into the ai...   \n",
       "4    1. Emissions: the release of gases into the ai...   \n",
       "..                                                 ...   \n",
       "442  1. Emissions Regulations: Rules and laws that ...   \n",
       "443  1. Assisted natural regeneration - This means ...   \n",
       "444  1. Unsustainable - This means that something c...   \n",
       "445  1. Drought - a prolonged period of dry weather...   \n",
       "446  1. Drought - a prolonged period of dry weather...   \n",
       "\n",
       "                                               address        lat         lon  \n",
       "0                                        United States  39.783730 -100.445882  \n",
       "1                                            Australia -24.776109  134.755000  \n",
       "2                                                   中国  35.000074  104.999927  \n",
       "3                                                   Ōu  51.000000   10.000000  \n",
       "4                                       United Kingdom  54.702354   -3.276575  \n",
       "..                                                 ...        ...         ...  \n",
       "442  Hollywood, Los Angeles, Los Angeles County, CA...  34.098003 -118.329523  \n",
       "443                                             Brasil -10.333333  -53.200000  \n",
       "444                                               Asia  51.208697   89.234375  \n",
       "445                             Монгол улс ᠮᠤᠩᠭᠤᠯ ᠤᠯᠤᠰ  46.825039  103.849974  \n",
       "446                             Монгол улс ᠮᠤᠩᠭᠤᠯ ᠤᠯᠤᠰ  46.825039  103.849974  \n",
       "\n",
       "[447 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:, 7:]\n",
    "df = df.dropna()\n",
    "rows_to_drop = []\n",
    "for i in range(len(df)):\n",
    "    if \"Earth\" in df.iloc[i, 7]:\n",
    "        rows_to_drop.append(i)\n",
    "df.to_csv('big_dataset_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Series is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 42\u001b[0m\n\u001b[0;32m     35\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[0;32m     36\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39mJohn\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mJane\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBob\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     37\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mage\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m25\u001b[39m, \u001b[39m30\u001b[39m, \u001b[39m40\u001b[39m],\n\u001b[0;32m     38\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlocation\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39mNew York\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLos Angeles\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mChicago\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     39\u001b[0m })\n\u001b[0;32m     41\u001b[0m df\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mexample_table\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 42\u001b[0m df_to_sqlite_json(df, \u001b[39m\"\u001b[39;49m\u001b[39mexample.sqlite.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[10], line 32\u001b[0m, in \u001b[0;36mdf_to_sqlite_json\u001b[1;34m(df, file_path)\u001b[0m\n\u001b[0;32m     30\u001b[0m json\u001b[39m.\u001b[39mdump(table_data, f)\n\u001b[0;32m     31\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m json\u001b[39m.\u001b[39;49mdump(db_metadata, f)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(skipkeys\u001b[39m=\u001b[39mskipkeys, ensure_ascii\u001b[39m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[39m=\u001b[39mcheck_circular, allow_nan\u001b[39m=\u001b[39mallow_nan, indent\u001b[39m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[39m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[39m=\u001b[39mdefault, sort_keys\u001b[39m=\u001b[39msort_keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\u001b[39m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[39m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[39m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m    180\u001b[0m     fp\u001b[39m.\u001b[39mwrite(chunk)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\json\\encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[39myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    430\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mdict\u001b[39m):\n\u001b[1;32m--> 431\u001b[0m     \u001b[39myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[39m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[39myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m newline_indent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\json\\encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m             chunks \u001b[39m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 325\u001b[0m         \u001b[39myield from\u001b[39;00m chunks\n\u001b[0;32m    326\u001b[0m \u001b[39mif\u001b[39;00m newline_indent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     _current_indent_level \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[39m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[39myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m newline_indent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\json\\encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCircular reference detected\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m     markers[markerid] \u001b[39m=\u001b[39m o\n\u001b[1;32m--> 438\u001b[0m o \u001b[39m=\u001b[39m _default(o)\n\u001b[0;32m    439\u001b[0m \u001b[39myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    440\u001b[0m \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\hackdartmouth\\lib\\json\\encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[0;32m    161\u001b[0m     \u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    180\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type Series is not JSON serializable"
     ]
    }
   ],
   "source": [
    "\n",
    "def df_to_sqlite_json(df, file_path):\n",
    "    # Create a dictionary to store the table data\n",
    "    table_data = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Convert the row data to a dictionary\n",
    "        row_data = row.to_dict()\n",
    "        # Add the row data to the table data list\n",
    "        table_data.append(row_data)\n",
    "\n",
    "    # Create a dictionary to store the table schema\n",
    "    table_schema = {}\n",
    "    for column in df.columns:\n",
    "        table_schema[column] = str(df[column].dtype)\n",
    "\n",
    "    # Create a dictionary to store the table metadata\n",
    "    table_metadata = {\n",
    "        \"name\": df.name,\n",
    "        \"schema\": table_schema\n",
    "    }\n",
    "\n",
    "    # Create a dictionary to store the database metadata\n",
    "    db_metadata = {\n",
    "        \"tables\": [table_metadata]\n",
    "    }\n",
    "\n",
    "    # Write the database metadata and table data to the JSON file\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(table_data, f)\n",
    "        f.write('\\n')\n",
    "        json.dump(db_metadata, f)\n",
    "\n",
    "# Example usage\n",
    "df = pd.DataFrame({\n",
    "    \"name\": [\"John\", \"Jane\", \"Bob\"],\n",
    "    \"age\": [25, 30, 40],\n",
    "    \"location\": [\"New York\", \"Los Angeles\", \"Chicago\"]\n",
    "})\n",
    "\n",
    "df.name = \"example_table\"\n",
    "df_to_sqlite_json(df, \"example.sqlite.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackdartmouth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
